<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Elliot Lake</title>
    <link>//localhost:1313/posts/</link>
    <description>Recent content in Posts on Elliot Lake</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 27 Jun 2025 16:31:48 +0100</lastBuildDate>
    <atom:link href="//localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>8 Months of Professional AI Development : A Retrospective</title>
      <link>//localhost:1313/posts/retrospective-ai-2025/</link>
      <pubDate>Fri, 27 Jun 2025 16:31:48 +0100</pubDate>
      <guid>//localhost:1313/posts/retrospective-ai-2025/</guid>
      <description>&lt;p&gt;At my current workplace, which is critical national infrastructure in the UK, we have been investigating possible uses for LLMs and other AI systems. As a developer with a Graduate Degree in the subject, I have been assigned to investigate possible use cases for the business since the end of January&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; this year. Throughout this process, and a not negligible amount of development with LLMs on the side, I have been increasingly less and less convinced by LLMs as something useful outside of very specific contexts, but that they&amp;rsquo;re not completely useless. In particular, I have found working with local LLMs to be a disappointing experience. This may be surprising to some readers, but I have found writing software systems with LLMs as an integral part of their operation to be a generally frustrating experience, even after implementing Prompt Engineering techniques suggested by figures such as Andrew Ng.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
